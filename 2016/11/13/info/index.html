<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
      <meta name="Author" content="Bryan Ford">
    
    <title>
  Rethinking Social Media to Escape the Echo Chamber &ndash; Bryan Ford&#39;s Home Page
</title>
    <link rel="shortcut icon" href="/img/favicon.ico"
	type="image/x-icon" />
    
    
    
  </head>

  <body 
  	
  	>
    
      <center>
<table bgcolor="black" cellspacing=1 cellpadding=4>
<tr><td bgcolor="white">
<font color=black>
<a href="/"><font color=blue>Home</font></a> -
<a href="/post"><font color=blue>Blog</font></a> -
<a href="/pub"><font color=blue>Publications</font></a> -
<a href="/cv.pdf"><font color=blue>CV</font></a> -
<a href="/draft"><font color=blue>Scribblings</font></a> -
<a href="/album/"><font color=blue>Photo Album</font></a> -
<a href="/funny/"><font color=blue>Funny</font></a>
</font>
</td></tr></table>
</center>
<p>

    

    
  <h1>Rethinking Social Media to Escape the Echo Chamber</h1>
  

<p>Hillary Clinton&rsquo;s [electoral college defeat]()
has provoked many questions about how so many Americans
could have choosen a
[misogynistic](),
[xenophobic](),
[pathologically lying](),
[authoritarian]()
[ideologue]()
as their next President &ndash;
and one of many targets of their blame is
[social media]().
Compounding its
[polarizing &ldquo;echo chamber&rdquo; effect](),
online discussions were tarnished with
[deliberate misinformation](),
including
[incorrect instructions on how to vote]().
But is the solution for social media companies like Facebook
to ``do a better job&rdquo; at curating the world&rsquo;s content
to suppress out false or hateful speech?</p>

<p>Asking technology companies
to serve as the world&rsquo;s arbiters of truth and civility
is not only counterproductive but
just as profoundly dangerous as the social maladies
that social media creates or exacerbates.
We need to rethink social media from the ground up
to make it <em>more</em> open and transparent, not less &ndash;
and most importantly, to infuse online debate with
some semblance of democratic legitimacy.
The purpose of this blog post is not to dwell on
[the many flaws of social media]()
but to explore how we could get it better.</p>

<p>What would an ethical, secure, and democratic alternative
to either conventional ``elitist&rdquo; media
or the polarizing echo chamber of social media look like?
It would need to be built on a foundation of equality among
all <em>real</em> people;
it would ensure <em>proportional</em> speech and accurately expose biases;
it would counteract polarization by ensuring that
all participants are exposed to all viewpoints;
and it would provide strong but proportionate and abuse-resistant
protections for anonymity and free speech <em>before</em> the ballot box,
in order to head off unpleasant surprises being revealed
only <em>at</em> the ballot box.</p>

<h2 id="foundation-the-equality-of-real-people">Foundation: The Equality of <em>Real</em> People</h2>

<p>When a story or claim appears with 1,000 ``likes&rdquo;,
how do we know whether 1,000 <em>real</em> people liked the story,
or only one real troll and his 999 [sock puppet accounts]()?</p>

<p>Doesn&rsquo;t mean all people are equally smart, equally capable, equally right,
or should end up having equal power or influence <em>in the end</em>.
It means all people should be given an equal <em>starting point</em>
in apportioning power,
and be free to ``become unequal&rdquo; as their words and actions
are subject to the review of their peers.</p>

<p>Need to be able to quantify the number of people</p>

<p>Need a mechanism to ensure that these are <em>real</em> people we are counting,
not fake accounts created
by whoever has the most time, money, or determination.</p>

<p>Content-based analysis versus account validation.
Content-based analysis [has often proven successful](),
but relies on complex algorithms that <em>someone</em> must keep updating
(and making still more complex)
to keep up with the ``arms race&rdquo;,
as attackers develop more sophisticated algorithms
to farm fake accounts that remain under the detection radar.
Relying on complex algorithms that need to adapt constantly
creates inherent risks that they will become opaque and vulnerable
to accidental bias or deliberate attacks,
such as the secret inclusion of &ldquo;back doors&rdquo; that produces false positives
designed to close the accounts of and hence disenfranchise populations
disfavored by the attacker.
While I believe content-based analysis plays an important scientific role,
it is unsuitable as a <em>foundation</em> for ensuring the equality of real people
in online public discourse.</p>

<h2 id="proportional-speech-and-bias-transparency">Proportional Speech and Bias Transparency</h2>

<p>Need an objective way to avoid bias,
or clearly and quantitatively expose it when it exists.</p>

<p>&hellip;like wearing blinders&hellip;</p>

<p>Pressuring Mark Zuckerberg to deploy Facebook&rsquo;s minions
to do a better job of censoring fake or misleading social media posts
does not solve the problem,
but instead shifts the power to decide between ultimate truth and falsehood
to precisely the place it does not belong:
to the anonymous employees and proprietary algorithms
of corporations that are accountable to no one but their shareholders.</p>

<p>All relevant algorithms need to be public and accountable.
Algorithms need to be as simple as possible
[but no simpler]():
in particular, not so simplistic as to ignore the many lessons
from past failures.</p>

<p>A fake or misleading claim on social media,
as soon as it starts collecting nontrivial interest,
needs to become inextricably attached to the counter-claims that debunk it.
These counter-claims must prominently include
accurate, quantitative evidence that the debunking experts are trustworthy
and not <a href="Ebell guy">paid lobbyists masquerading as scientists</a> &ndash;
together with accurate quantitative measures of the number of people
(<em>real</em> people) who support the false statement despite its being debunked.</p>

<h2 id="depolarizing-echo-chambers-with-soft-focus-feeds">Depolarizing Echo Chambers with Soft-Focus Feeds</h2>

<p>Even when people are willing to hear viewpoints they don&rsquo;t like,
there is a matter of scalability:
everyone simply does not have time to listen to everything everyone else says.
Speech needs to be filtered or summarized.</p>

<h2 id="anonymity-and-free-speech-before-the-ballot-box">Anonymity and Free Speech <em>Before</em> the Ballot Box</h2>

<p>one of many explanations, possibly contributing but probably not only factor&hellip;
other explanations include
[normal polling errors](),
[hacking of the election system](),
[the FBI](), &hellip;</p>

<p>Some Trump supporters are certainly racist and xenophobic;
most of them are probably not,
but voted Trump for other reasons.
In order to protect our civilization,
we the people need to be fully aware of size and malignancy of
any malignancy affecting it:
you do not beat a cancerous tumor by ignoring it
or sanitizing the doctor&rsquo;s diagnosis.
We need <em>know</em> the true, complex set of reasons that
people are inclined to support someone like Trump</p>

<p>Need regular opportunities for speech
ensuring that <em>all</em> voices are represented,
and [building anger over policies]()
actually have [a chance to influence policy]()
before that anger
explodes in a self-defeating electoral choice
of an [authoritarian]() [con-artist]()
and [places freedom and democracy in existential risk]().</p>

<h2 id="incentives-who-will-finance-a-decentralized-social-forum">Incentives: Who Will Finance a Decentralized Social Forum?</h2>

<!--
---

*I wish to thank ...
for helpful feedback on early drafts of this post.*
-->



    
      <br clear=all>
<hr>
<table width="100%"><tr>
<td align="left">
<a href="https://bford.info/">Bryan Ford</a>
</td>
<td align="right">
<font size="-2">
 
</font>
</td></tr></table>

    
  </body>
</html>
